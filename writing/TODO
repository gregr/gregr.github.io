alternative-to-macros-and-fexprs
  best of both worlds? statically-determined operative behavior as in minikernel
  static reasoning:
    does a combination/call-site behave like a procedure application or an operative/macro invocation?
    this is important for avoiding unintentional context capture and enabling local analysis/reasoning/optimization
    comparison
      hygienic scheme macros:
        macro/procedure behavior is determined statically, based on syntactic class of let-defined names (let: definition body must be immediately present)
        unintentional context capture statically preventable
        amenable to local reasoning after mandatory partial evaluation (aka macro expansion)
      kernel:
        operative/applicative behavior is determined at runtime, based on whether the invoked combiner (procedure-like object) is 'wrapped' as an applicative
        unintentional context capture mitigated via operative naming conventions ($-prefixes); higher-order abstractions leak by default (operand capture)
        significant non-local partial evaluation may be required to support reasoning
      minikernel:
        operative/applicative behavior is determined statically, based on syntactic class of lambda-defined names (lambda: definition body may be deferred)
        unintentional context capture statically preventable
        amenable to local reasoning after optional partial evaluation
  implementation complexity:
    how complex is the task of implementing new abstractions while maintaining hygiene?
    comparison
      hygienic scheme macros:
        within the reach of syntax-rules, complexity is not terrible, but syntax-rules is not practical for much more than sugar
        beyond syntax-rules, complexity quickly becomes onerous
      kernel and minikernel:
        implementations directly compute their results with the benefit of lexical scope and the dynamic calling environment
        no need to juggle/arrange/prepare syntax for a later expansion phase that won't otherwise have the right context available to map identifiers correctly

many futures of programming
  Learnable Programming: http://worrydream.com/LearnableProgramming/
  Unison: http://unisonweb.org/
  Subtext: http://www.subtext-lang.org/
  Eve: http://incidentalcomplexity.com/
  Aquameta: http://www.aquameta.com/
  Reactive Demand Programming: https://awelonblue.wordpress.com/category/language-design/reactive-demand-programming/
  Bloom: http://www.bloom-lang.net/

domain-specific programming tools
  http://www.evanmiller.org/dont-kill-math.html
  can accept that code is made up of symbols
    this is acknowledged in drawing dyn viz
    whether or not the code is represented as plain text, or in a more diagrammatic way
  having to comprehend the generalizations described by code simply by reading text and simulating the behavior in your mind involves super-human effort and should be unnecessary; comprehension of the concrete is direct and often effortless (exceptions involve data too large for the mind, requiring exploration/navigation; but this is still not an unnatural effort)
    can comprehension of code be made more direct by interactively visualizing the program's transformation as concrete data flows through it? is there a better approach than this?
  output/effect of running code is concrete
  code is currently written directly
  why not instead write code with tools for manipulating the concrete, then generalizing?
    leverage the directness of the concrete medium to know what output you'll be getting with much more certainty
    explicit generalization by indicating/marking important concrete features and their relationships
    tools for implicit generalization might involve machine learning
  are symbols unavoidable when manipulating the abstract?
    you can describe values concretely given enough context
    can you describe actions/operations concretely?
      as machines? but how do you describe these machines without even more context?
        for instance, a specific pixel-based drawing requires only a grid of colored pixels
        to then describe machines that manipulate pixel drawings requires adding even more concepts
          these additional concepts seem to be symbols, reinvented
        even if you don't agree that you need to reinvent symbols to describe machines, once you are dealing with machines you are back where you started:
          the problem of having to simulate their behavior to perform analysis
          it seems the best we can do is provide tools that assist with this simulation?

conveniently ubiquitous programming via html-embedded editor widgets
  widget allows page-local manipulation/execution
  can be rendered chrome-less (for seamless appearance) or expanded into the full editor in-page
  can connect to externally hosted DBs to import/export additional programs/content
    browsing a page with embedded code widgets and want to ...
      ... interact with the embedded code later? export a reference/copy to your personal DB
      ... interact with the embedded code while incorporating some of your own code? immediately import it from your personal DB
    on top of serendipitous programming, enables working on personal projects from anywhere
      assumes you trust the machine you run the browser on, or provide some other security mechanism, such as accessing revoke-able and/or read-only DB capabilities
  editor can support more than just "code" editing
    symbol manipulation (typical programming), graphics, sound, arbitrary html, other domain-specific editing
      arbitrary html would mean you can run the editor in the editor...
      similar ideas? http://blog.duangle.com/2015/01/conspire-programming-environment-for.html

understandable programming (improve math)
  what we almost, but not quite, have now: symbolic manipulation
    what is my program doing?
      operational semantics: small steps; step in any order
        typically verbose, unidirectional
        we have stepping debuggers, but not many such tools for exploration via assisted program transformation: we can only step straight through in one order
      abstract over small steps: provable equivalences; proof by rewriting
        domain-specific symbolic reasoning
        we have mostly-automatic systems like ACL2, but limited to first order
        can do some of this in higher order systems like Coq
    why does my program work?
      write simple declarative statements describing properties of your program
      prove that these statements are true: proof is the explanation of why
        caveats
          essential complexity remains
          no guarantee that an automated solution will produce lucid proofs/explanations
          but manual intervention can be supported and automation can be improved
  can we do better?
    express some ideas more directly with alternative paradigms
      truth maintenance
      temporal logic
    we don't really have this yet: alternative channels of representation (not limited to visualization)
      improved communication with our biological hardware
      algebra and geometry
      what is my program doing?
        library authors provide the following
          domain-specific data representations (such as images)
            can be embedded directly in symbolic programs alongside other code
          representative examples and random example generation for each class of data (similar to quicktest)
            examples of compound data can be automatically synthesized if examples of sub-data already exist
          certain operations marked as meaningful high-level steps
          input->output representation interpolations for each of these operations/steps (motion, fade in/out, etc.)
        using these libraries, programmers then
          compose programs using domain-specific operations
          interact with them using either specific or library-provided representative/random example data
            high-level stepping
            abstract over steps: lump multiple steps into animations; lump animations together as new animations
      why does my program work?
        visual proofs: explanatory images, diagrams and animations
        https://mathoverflow.net/questions/8846/proofs-without-words
      can we do even better?
        use these libraries to build domain-specific editing tools (including using a domain-specific editing tool for making such tools!)
          no longer editing code directly; editing medium of interest directly
        might look something like: drawing dynamic visualizations
      can we still do even better?
        hitting limits of conventional hardware, so create new hardware
          seeing spaces
          humane representation of thought

bash syntax highlighting css
  samp (sample output)
    http://www.w3.org/TR/html5/text-level-semantics.html#the-samp-element
  kbd (keyboard input)
    http://www.w3.org/TR/html5/text-level-semantics.html#the-kbd-element
  var

macro-writing tips; continuation-passing-ish syntax-rules

alternatives to macro-like syntactic transformation
  address frankenprogramming

open recursion in data and functions
  explain how to write fold/eval for such structures
    consider racket (dynamic types)
  mention possibility of using typeclasses
  maybe tie into: tail call optimization is not a red herring (guy steele)

output-event sourcing (decision sourcing)
  vs. input-event sourcing (command sourcing)
  appropriate for online (as in https://en.wikipedia.org/wiki/Online_algorithm), reactive systems
  diagram:
    input-event/request -> decide (state -> input-event -> output-event/decision) -> log decision (example: kafka) -> update (state -> decision -> state) -> commit (write the actual updated state; example: rdbms) -> schedule/trigger downstream processes (send emails? launch missiles?) -> render views -> response
    draw decision and new state flow through pipeline
    point out mostly-pure functions making use of db/state interface
      can still be thought of as pure functions if db:get is an interface to an immutable structure
  scaling:
    data size: external state storage
    parallelism: multiple instances
      consistency and availability trade-offs in design
      instances in lock-step vs. merges of state updates, CRDTs, etc.
      single instance not even necessarily a synchronous pipeline under some trade-offs: delayed feedback of updated state into 'decide'
      crashing/restarting, state rebuilding, time to catch up

ambitious project description
  enhanced interpreter for a small extension of the lambda calculus + supporting tools
    calculus
      unit, bit, pair, pair-access, lam, lam-apply
      de Bruijn indices and explicit substitutions
      bubbling-up binders for side effects
    small-step operational semantics + induction rule + proof checker = equational reasoning tools
      provable property/specification satisfaction
      provably-correct program transformations
        exploration
        program inference
          run programs "backwards"
          automated theorem proving (proof inference a special case of program inference)
        refactoring
        debugging
        optimization
          programmable automation (rule-based, supercompilation, etc.)
          also can be manually-driven via editor
        compilation
          model an abstract machine, then translate to it
    higher-level language encodings
      meta interpretation, denotational semantics
  static type systems, control-flow analyses, etc. as special cases of theorem proving
  typeclasses via term inference
  structure (AST) editor
  viable target for importing, analyzing, transforming, exporting programs written in more common languages
    ideally end up as the hub in a hub-and-spokes organization
